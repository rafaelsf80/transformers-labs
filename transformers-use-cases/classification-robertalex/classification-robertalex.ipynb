{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution 3. Inferencia RoBERTalex\n",
    "\n",
    "RoBERTalex es un transformer en español basado en RoBERTa, que se ha entrenado con un dataset en materia legal de 8.9GB de texto.\n",
    "\n",
    "RoBERTalex se puede usar directamente para la tarea de Fill Mask task (ver ejemplo). \n",
    "\n",
    "Pero lo normal es hacer un full fine-tuning ara tareas como Question Answering, Text Classification, o Named Entity Recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inferencia simple\n",
    "from transformers import pipeline\n",
    "from pprint import pprint\n",
    "unmasker = pipeline('fill-mask', model='PlanTL-GOB-ES/RoBERTalex')\n",
    "print(unmasker(\"La ley fue <mask> finalmente.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver Tamaño de embeddings\n",
    "\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "tokenizer = RobertaTokenizer.from_pretrained('PlanTL-GOB-ES/RoBERTalex')\n",
    "model = RobertaModel.from_pretrained('PlanTL-GOB-ES/RoBERTalex')\n",
    "text = \"Gracias a los datos legales se ha podido desarrollar este modelo del lenguaje.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "print(output.last_hidden_state.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
