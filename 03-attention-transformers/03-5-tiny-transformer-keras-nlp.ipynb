{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03-5: Tiny encoder transformer Keras 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# You should reinstall Keras 3 after installing KerasNLP\n",
    "!pip install -q --upgrade keras-nlp\n",
    "!pip install -q --upgrade keras  # Upgrade to Keras 3.\n",
    "\n",
    "#!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "#!tar -xf aclImdb_v1.tar.gz\n",
    "#!# Remove unsupervised examples\n",
    "#!rm -r aclImdb/train/unsup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # or \"tensorflow\" or \"torch\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras_nlp\n",
    "import keras\n",
    "\n",
    "# Use mixed precision to speed up all training in this guide.\n",
    "keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "imdb_train = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/train\",\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "imdb_test = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/test\",\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "vocab = keras_nlp.tokenizers.compute_word_piece_vocabulary(\n",
    "    imdb_train.map(lambda x, y: x),\n",
    "    vocabulary_size=20_000,\n",
    "    lowercase=True,\n",
    "    strip_accents=True,\n",
    "    reserved_tokens=[\"[PAD]\", \"[START]\", \"[END]\", \"[MASK]\", \"[UNK]\"],\n",
    ")\n",
    "tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
    "    vocabulary=vocab,\n",
    "    lowercase=True,\n",
    "    strip_accents=True,\n",
    "    oov_token=\"[UNK]\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data with a custom tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packer = keras_nlp.layers.StartEndPacker(\n",
    "    start_value=tokenizer.token_to_id(\"[START]\"),\n",
    "    end_value=tokenizer.token_to_id(\"[END]\"),\n",
    "    pad_value=tokenizer.token_to_id(\"[PAD]\"),\n",
    "    sequence_length=512,\n",
    ")\n",
    "\n",
    "\n",
    "def preprocess(x, y):\n",
    "    token_ids = packer(tokenizer(x))\n",
    "    return token_ids, y\n",
    "\n",
    "\n",
    "imdb_preproc_train_ds = imdb_train.map(\n",
    "    preprocess, num_parallel_calls=tf.data.AUTOTUNE\n",
    ").prefetch(tf.data.AUTOTUNE)\n",
    "imdb_preproc_val_ds = imdb_test.map(\n",
    "    preprocess, num_parallel_calls=tf.data.AUTOTUNE\n",
    ").prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(imdb_preproc_train_ds.unbatch().take(1).get_single_element())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design a tiny transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create model for a tiny transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the transformer directly on the classification objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compile and train tiny transformer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
